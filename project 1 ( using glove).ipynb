{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding,LSTM\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting XML data and save it in a list and assigning labels to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "path1=cwd + '/'+ 'data'\n",
    "train_data=os.path.join(path1+'/'+'train,val,test')\n",
    "\n",
    "xml_data=[]\n",
    "labels = []\n",
    "for label_type in ['benxml' , 'malxml']:\n",
    "    dir_name=os.path.join(train_data,label_type)\n",
    "    \n",
    "    for fname in os.listdir(dir_name):\n",
    "        dat=os.path.join(dir_name,fname)\n",
    "        f= open(dat,'r').read().split(',')\n",
    "        xml_data.append(f[0])\n",
    "        \n",
    "        if label_type == 'benxml':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the list data's to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<manifest android:versionCode=\"21\" android:versionName=\"2.7\" android:installLocation=\"preferExternal\" package=\"hu.butcher.nyanCat\"\n",
      "  xmlns:android=\"http://schemas.android.com/apk/res/android\">\n",
      "    <application android:label=\"@string/app_name\" android:icon=\"@drawable/icon\" android:hardwareAccelerated=\"true\">\n",
      "        <activity android:label=\"@string/app_name\" android:name=\".activites.Hall\" android:clearTaskOnLaunch=\"true\" android:screenOrientation=\"landscape\">\n",
      "            <intent-filter>\n",
      "                <action android:name=\"android.intent.action.MAIN\" />\n",
      "                <category android:name=\"android.intent.category.LAUNCHER\" />\n",
      "            </intent-filter>\n",
      "        </activity>\n",
      "        <activity android:label=\"@string/app_name\" android:name=\".activites.Game\" android:clearTaskOnLaunch=\"true\" android:screenOrientation=\"landscape\" />\n",
      "        <activity android:label=\"@string/app_name\" android:name=\".activites.GameComplete\" android:clearTaskOnLaunch=\"true\" android:screenOrientation=\"landscape\" />\n",
      "        <activity android:label=\"@string/app_name\" android:name=\".activites.ControlsSelect\" android:clearTaskOnLaunch=\"true\" android:screenOrientation=\"landscape\" />\n",
      "        <activity android:label=\"@string/app_name\" android:name=\".activites.Info\" android:clearTaskOnLaunch=\"true\" android:screenOrientation=\"landscape\" />\n",
      "        <activity android:name=\"com.google.ads.AdActivity\" android:configChanges=\"keyboard|keyboardHidden|orientation\" />\n",
      "    </application>\n",
      "    <uses-permission android:name=\"android.permission.VIBRATE\" />\n",
      "    <uses-permission android:name=\"android.permission.WAKE_LOCK\" />\n",
      "    <uses-permission android:name=\"android.permission.INTERNET\" />\n",
      "    <uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" />\n",
      "    <supports-screens android:anyDensity=\"true\" android:smallScreens=\"true\" android:normalScreens=\"true\" android:largeScreens=\"true\" android:xlargeScreens=\"true\" />\n",
      "</manifest>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (xml_data[0])\n",
    "print (labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11827\n",
      "11827\n"
     ]
    }
   ],
   "source": [
    "print (len(xml_data))\n",
    "print (len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting and Tokenizing the xml data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 66081 unique tokens\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(num_words=None,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', \\\n",
    "         lower=True, split=' ', char_level=False, oov_token=None)\n",
    "\n",
    "tokenizer.fit_on_texts(xml_data)\n",
    "sequences=tokenizer.texts_to_sequences(xml_data)\n",
    "word_index=tokenizer.word_index\n",
    "print ('found %s unique tokens' %(len(word_index)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321\n"
     ]
    }
   ],
   "source": [
    "q=[]\n",
    "for i in sequences:\n",
    "    s=len(i)\n",
    "    q.append(s)\n",
    "    s=max(q)\n",
    "print (s)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As benign and malicious data is continous we are shuffling before making train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pad_sequences(sequences,maxlen=s)\n",
    "labels=np.array(labels)\n",
    "xml_data=np.array(xml_data)\n",
    "indices=np.arange(data.shape[0])\n",
    "indices1=np.arange(labels.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "np.random.shuffle(indices1)\n",
    "\n",
    "data=data[indices]\n",
    "labels=labels[indices1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making training (60%) and test data (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data,labels,test_size=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing glove pretrained weights from different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir=os.getcwd()\n",
    "path=glove_dir + '/'+ 'glove.6B'\n",
    "embeddings_index={}\n",
    "f=open(os.path.join(path,'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype='float32')\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing word embedding marix to give to embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((66082,100))\n",
    "for word, i in word_index.items():\n",
    "    if i < 66082:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 12321, 100)        6608200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,729,609\n",
      "Trainable params: 6,729,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(66082,100,input_length=s))\n",
    "#model.add(Flatten())\n",
    "model.add(LSTM(128,dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading glove embeddings into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7096 samples, validate on 4731 samples\n",
      "Epoch 1/2\n",
      "6688/7096 [===========================>..] - ETA: 2:24 - loss: 0.6919 - acc: 0.5312"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='RMSprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "history=model.fit(x_train,y_train,epochs=2,validation_data=(x_test,y_test),batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting for test data and and giving the criteria for binary classification the values below and equal to 0.5 is class 0 benign and above 0.5 is class 1 malicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict(x_test,batch_size=32)\n",
    "for i in range(len(preds)):\n",
    "    if preds[i]<=0.5:\n",
    "        temp=0\n",
    "        preds[i]=temp\n",
    "    else:\n",
    "        preds[i]=1\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eva=model.evaluate(x_test,y_test)\n",
    "print (eva)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['train','val'],loc= 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test,preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix=confusion_matrix(y_test,preds)\n",
    "print (cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roc auc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
